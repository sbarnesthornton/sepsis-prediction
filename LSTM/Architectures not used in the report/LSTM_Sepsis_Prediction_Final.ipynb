{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy1RhhCBcouH",
        "outputId": "b507084e-c323-48a1-c96b-f49111eaf5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-HIW7wwcwnC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as skm\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.utils import resample\n",
        "import math\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics import f1_score,roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7ps2sU5fLKm"
      },
      "outputs": [],
      "source": [
        "def getpatientstay(patient,df):\n",
        "  return df['Patient_ID'].value_counts().get(patient, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQNiRjsPi6-k"
      },
      "outputs": [],
      "source": [
        "# Load Date\n",
        "df =pd.read_csv('/content/drive/MyDrive/DataScience/project/no_additional_features.zip (Unzipped Files)/train_set_interpolation_with_multivariate.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdQkIU55e2kg"
      },
      "outputs": [],
      "source": [
        "### DataFrame funcs\n",
        "\n",
        "for patient in df.Patient_ID.unique():\n",
        "  patient = int(patient)\n",
        "  # Get patient length stay#\n",
        "  patient_stay = getpatientstay(patient,df)\n",
        "  if patient_stay<=12:\n",
        "    df = df.loc[df['Patient_ID'] != patient]\n",
        "  num_sepsis_readings= df.loc[df['Patient_ID'] == patient, 'SepsisLabel'].sum()\n",
        "  if num_sepsis_readings <6:\n",
        "    df = df.loc[df['Patient_ID'] != patient]\n",
        "\n",
        "\n",
        "# return patient cleaned df and seperate into train and test sets\n",
        "# y = df.SepsisLabel\n",
        "# X = df.drop(['SepsisLabel'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRikcPQAs2Ce"
      },
      "outputs": [],
      "source": [
        "df.to_csv('cleanedLSTMdata.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4vqPaiPvjRR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMYvMPCntnQB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SlLFxMjtw_a"
      },
      "outputs": [],
      "source": [
        "# Define the proportion of data to be allocated to each set\n",
        "train_proportion = 0.7\n",
        "val_proportion = 0.15\n",
        "test_proportion = 0.15\n",
        "\n",
        "# Load the data into a pandas dataframe\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/DataScience/project/cleanedLSTMdata.csv\")\n",
        "\n",
        "\n",
        "# Group the data by patient ID\n",
        "grouped = df.groupby(\"Patient_ID\")\n",
        "\n",
        "# Shuffle the groups\n",
        "grouped = grouped.sample(frac=1, random_state=42)\n",
        "\n",
        "# Split the shuffled groups into train, validation, and test sets\n",
        "train_size = int(len(grouped) * train_proportion)\n",
        "val_size = int(len(grouped) * val_proportion)\n",
        "test_size = int(len(grouped) * test_proportion)\n",
        "\n",
        "train_groups = grouped.head(train_size).index.values\n",
        "val_groups = grouped[train_size:train_size+val_size].index.values\n",
        "test_groups = grouped[-test_size:].index.values\n",
        "\n",
        "# Concatenate the rows from each group in each set back into a single dataframe\n",
        "train_df = df.loc[train_groups]\n",
        "val_df = df.loc[val_groups]\n",
        "test_df = df.loc[test_groups]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MyO9r2sjxhuj"
      },
      "outputs": [],
      "source": [
        "### Define model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM, Dropout\n",
        "# model_lstm = Sequential()\n",
        "# model_lstm.add(LSTM(20,activation='tanh', return_sequences=True,input_shape=(12, train_df.shape[1]-1)))\n",
        "# model_lstm.add(LSTM(20, return_sequences=True))\n",
        "# model_lstm.add(Dropout(0.2))\n",
        "# model_lstm.add(LSTM(6))\n",
        "# model_lstm.add(Dense(1))\n",
        "\n",
        "# model_lstm.compile(loss='mse', optimizer='adam')\n",
        "# model_lstm.summary()\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.InputLayer(input_shape=(1, 12, train_df.shape[1]-1)))\n",
        "model.add(tf.keras.layers.Conv2D(64, 1, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(2, padding=\"same\"))\n",
        "model.add(tf.keras.layers.LSTM(64, activation=\"tanh\"))\n",
        "model.add(tf.keras.layers.LSTM(32, activation=\"tanh\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.summary()\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(6))\n",
        "# model.add(tf.keras.layers.Activation(\"softmax\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "irlT-oY8cxEi"
      },
      "outputs": [],
      "source": [
        "y_val, y_test = val_df.SepsisLabel, test_df.SepsisLabel\n",
        "X_val,X_test = val_df.drop(['SepsisLabel'],axis=1), test_df.drop(['SepsisLabel'],axis=1)\n",
        "\n",
        "\n",
        "# Initialise model\n",
        "# Get patients list\n",
        "windowsize = 12\n",
        "epochs = 50\n",
        "batches_per_patient = 30\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch: ',epoch)\n",
        "  for patient in train_df.Patient_ID.unique():\n",
        "    print('Patient: ',patient)\n",
        "    # Get patients data\n",
        "    patient = int(patient)\n",
        "    patient_df = train_df[train_df.Patient_ID==patient]\n",
        "    for batch_per_patient in range(batches_per_patient):\n",
        "      # Randomly choose a starting integer, take the next 12 readigns as a batch\n",
        "      # Fit model for this batch\n",
        "      patient_stay = patient_df.shape[0]\n",
        "      batch_start = random.randint(0,patient_stay-windowsize)\n",
        "      batch_df = df.iloc[batch_start:batch_start+windowsize, :]\n",
        "      y_batch = batch_df.SepsisLabel\n",
        "      X_batch = batch_df.drop(['SepsisLabel'],axis=1).values\n",
        "      X_batch = X_batch.reshape(1,windowsize,batch_df.shape[1]-1)\n",
        "      y_batch = y_batch.values.reshape(1,windowsize)\n",
        "      model.fit(X_batch,y_batch,epochs=3,verbose=0)\n",
        "      # print(lstm_history)\n",
        "\n",
        "\n",
        "  # Validate model\n",
        "  if epoch % 5 != 0:\n",
        "        continue\n",
        "  # Validate model using val data\n",
        "  preds = model.predict(X_val)\n",
        "  print('| F1 Score: ',f1_score(y_val,preds,average = None), ' | roc auc score: ', roc_auc_score(y_val,preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICozN2GyEbEL"
      },
      "outputs": [],
      "source": [
        "epoch"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}